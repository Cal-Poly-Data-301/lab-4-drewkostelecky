{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewkostelecky/lab-4-drewkostelecky/blob/main/DATA_301_Lab_4_Drew_Kostelecky.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWSNdW_jY8DY"
      },
      "source": [
        "# Machine Learning for Beer\n",
        "\n",
        "Your goal is to train a model to predict the bitterness of a beer (in International Bittering Units, or IBU), given features about the beer. You can acquire the data in two places:\n",
        "\n",
        "- on [Kaggle](https://www.kaggle.com/c/beer2020/data) \n",
        "- on [Github](https://github.com/dlsun/pods/tree/master/data/beer) (https://dlsun.github.io/pods/data/beer/beer_train.csv and https://dlsun.github.io/pods/data/beer/beer_test.csv )\n",
        "\n",
        "A description of the variables is available [here](https://www.kaggle.com/c/beer2020/data).\n",
        "\n",
        "\n",
        "We would like to predict **ibu** using a $20$-nearest neighbors model.\n",
        "\n",
        "There are three features that have to do with the physical properties of the beer:  **abv**, **srm**, **original gravity**\n",
        "\n",
        "There are two \"cultural\" features that have to do with how/when the beer is traditionally served: **glass**, **available**\n",
        "\n",
        "Consider predicting **ibu** from \n",
        "(a) Only the physical features\n",
        "(b) Only the cultural features\n",
        "(c) All five features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_dir = \"https://dlsun.github.io/pods/data/beer/\"\n",
        "beer_train = pd.read_csv(data_dir + \"beer_train.csv\")\n",
        "beer_train[\"srm_quant\"] = beer_train[\"srm\"].map(lambda x: 41 if x == \"Over 40\" else int(x))\n",
        "beer_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "lQ5QMFfq91Pa",
        "outputId": "26f16bd9-e813-4c9e-e112-e578ed8cedcd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id   abv                                        available  \\\n",
              "0        0   8.2  Available at the same time of year, every year.   \n",
              "1        1   5.7  Available at the same time of year, every year.   \n",
              "2        2   5.8  Available at the same time of year, every year.   \n",
              "3        3   5.5           Available year round as a staple beer.   \n",
              "4        4   4.8           Available year round as a staple beer.   \n",
              "...    ...   ...                                              ...   \n",
              "5995  5995   5.5           Available year round as a staple beer.   \n",
              "5996  5996  11.0  Available at the same time of year, every year.   \n",
              "5997  5997   5.2           Available year round as a staple beer.   \n",
              "5998  5998   6.2                            Limited availability.   \n",
              "5999  5999   5.1           Available year round as a staple beer.   \n",
              "\n",
              "                                            description glass   ibu isOrganic  \\\n",
              "0     A Belgian-Abbey-Style Tripel that is big in al...   NaN  31.0         N   \n",
              "1     Covert Hops is a crafty ale. Its stealthy dark...  Pint  45.0         N   \n",
              "2     This is a traditional German-style Marzen char...   Mug  25.0         N   \n",
              "3     A West Coast-Style Pale Ale balancing plenty o...  Pint  55.0         N   \n",
              "4     This Bombshell has a tantalizing crisp and cle...  Pint  11.4         N   \n",
              "...                                                 ...   ...   ...       ...   \n",
              "5995  Taking its cues from “Three Threads”, a barten...  Pint  33.0         N   \n",
              "5996  Our barley wine is what would be considered an...   NaN  30.0         N   \n",
              "5997  Our version of a west coast pale ale pushes th...  Pint  45.0         N   \n",
              "5998  Aquarius White IPA combines the phenolic and e...   NaN  50.0         N   \n",
              "5999                                                NaN   NaN  23.0         N   \n",
              "\n",
              "                        name  originalGravity      srm  srm_quant  \n",
              "0            LoonyToonTripel            1.070        8          8  \n",
              "1                Covert Hops            1.056       35         35  \n",
              "2                Oktoberfest            1.048       10         10  \n",
              "3                   Pale Ale            1.044        5          5  \n",
              "4     Head Turner Blonde Ale            1.045        3          3  \n",
              "...                      ...              ...      ...        ...  \n",
              "5995        Mayflower Porter            1.040  Over 40         41  \n",
              "5996             Barbieswine            1.085       20         20  \n",
              "5997         Canuck Pale Ale            1.044        8          8  \n",
              "5998                Aquarius            1.044        2          2  \n",
              "5999               Amber Ale            1.048       15         15  \n",
              "\n",
              "[6000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d58c848-b23f-4645-a380-b0cd7f1a2e52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>abv</th>\n",
              "      <th>available</th>\n",
              "      <th>description</th>\n",
              "      <th>glass</th>\n",
              "      <th>ibu</th>\n",
              "      <th>isOrganic</th>\n",
              "      <th>name</th>\n",
              "      <th>originalGravity</th>\n",
              "      <th>srm</th>\n",
              "      <th>srm_quant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8.2</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>A Belgian-Abbey-Style Tripel that is big in al...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.0</td>\n",
              "      <td>N</td>\n",
              "      <td>LoonyToonTripel</td>\n",
              "      <td>1.070</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>Covert Hops is a crafty ale. Its stealthy dark...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>45.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Covert Hops</td>\n",
              "      <td>1.056</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>This is a traditional German-style Marzen char...</td>\n",
              "      <td>Mug</td>\n",
              "      <td>25.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Oktoberfest</td>\n",
              "      <td>1.048</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5.5</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>A West Coast-Style Pale Ale balancing plenty o...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>55.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Pale Ale</td>\n",
              "      <td>1.044</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.8</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>This Bombshell has a tantalizing crisp and cle...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>11.4</td>\n",
              "      <td>N</td>\n",
              "      <td>Head Turner Blonde Ale</td>\n",
              "      <td>1.045</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>5995</td>\n",
              "      <td>5.5</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>Taking its cues from “Three Threads”, a barten...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>33.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Mayflower Porter</td>\n",
              "      <td>1.040</td>\n",
              "      <td>Over 40</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>5996</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>Our barley wine is what would be considered an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Barbieswine</td>\n",
              "      <td>1.085</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>5997</td>\n",
              "      <td>5.2</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>Our version of a west coast pale ale pushes th...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>45.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Canuck Pale Ale</td>\n",
              "      <td>1.044</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>5998</td>\n",
              "      <td>6.2</td>\n",
              "      <td>Limited availability.</td>\n",
              "      <td>Aquarius White IPA combines the phenolic and e...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>1.044</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>5999</td>\n",
              "      <td>5.1</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Amber Ale</td>\n",
              "      <td>1.048</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d58c848-b23f-4645-a380-b0cd7f1a2e52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d58c848-b23f-4645-a380-b0cd7f1a2e52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d58c848-b23f-4645-a380-b0cd7f1a2e52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beer_test = pd.read_csv(data_dir + \"beer_test.csv\")\n",
        "beer_test[\"srm_quant\"] = beer_train[\"srm\"].map(lambda x: 41 if x == \"Over 40\" else int(x))\n",
        "beer_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0nfuJneH-XkK",
        "outputId": "418b2828-3cc0-4325-e31c-539db758d45f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id   abv                               available  \\\n",
              "0  6000  10.0                   Limited availability.   \n",
              "1  6001   5.2  Available year round as a staple beer.   \n",
              "2  6002   4.0     Available during the winter months.   \n",
              "3  6003  10.2  Available year round as a staple beer.   \n",
              "4  6004   6.0                   Limited availability.   \n",
              "\n",
              "                                         description  glass  ibu isOrganic  \\\n",
              "0  A classic Belgian Trappist style strong ale wi...  Tulip  NaN         N   \n",
              "1  An American-style of Pale Ale brewed with a ba...   Pint  NaN         N   \n",
              "2  This amber wheat ale has a balanced malt body,...  Tulip  NaN         Y   \n",
              "3  A uniquely large beer developed by taking our ...   Pint  NaN         N   \n",
              "4         An American red ale with crisp hop flavor.    NaN  NaN         N   \n",
              "\n",
              "                           name  originalGravity srm  srm_quant  \n",
              "0                     She WILL!            1.084  17          8  \n",
              "1    Defender American Pale Ale            1.044  22         35  \n",
              "2                         Hazel            1.036  19         10  \n",
              "3  Cinderella’s Twin Double IPA            1.087  11          5  \n",
              "4              Independence Ale            1.048  14          3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bd40e68-f837-4ec0-8bf0-86c030167110\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>abv</th>\n",
              "      <th>available</th>\n",
              "      <th>description</th>\n",
              "      <th>glass</th>\n",
              "      <th>ibu</th>\n",
              "      <th>isOrganic</th>\n",
              "      <th>name</th>\n",
              "      <th>originalGravity</th>\n",
              "      <th>srm</th>\n",
              "      <th>srm_quant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Limited availability.</td>\n",
              "      <td>A classic Belgian Trappist style strong ale wi...</td>\n",
              "      <td>Tulip</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>She WILL!</td>\n",
              "      <td>1.084</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6001</td>\n",
              "      <td>5.2</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>An American-style of Pale Ale brewed with a ba...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>Defender American Pale Ale</td>\n",
              "      <td>1.044</td>\n",
              "      <td>22</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6002</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Available during the winter months.</td>\n",
              "      <td>This amber wheat ale has a balanced malt body,...</td>\n",
              "      <td>Tulip</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hazel</td>\n",
              "      <td>1.036</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6003</td>\n",
              "      <td>10.2</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>A uniquely large beer developed by taking our ...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>Cinderella’s Twin Double IPA</td>\n",
              "      <td>1.087</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6004</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Limited availability.</td>\n",
              "      <td>An American red ale with crisp hop flavor.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>Independence Ale</td>\n",
              "      <td>1.048</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bd40e68-f837-4ec0-8bf0-86c030167110')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bd40e68-f837-4ec0-8bf0-86c030167110 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bd40e68-f837-4ec0-8bf0-86c030167110');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEBlEDxWY8Dl"
      },
      "source": [
        "## Question 1\n",
        "Let's see how the distance metric, the scaling method, and the model influence prediction accuracy. \n",
        "\n",
        "Consider only the *physical* features. Train a **20**-nearest-neighbor model to predict **ibu**. Try fitting models with different distance metrics and scaling methods. \n",
        "\n",
        "Which distance metric and/or scaling method gives the best prediction accuracy? Why do you think that might be?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]], y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_p_std = pipeline.predict(beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "rmse_euc_p_std = np.sqrt(np.mean((beer_train_predicts_euc_p_std - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_p_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWWBRTNI_VlE",
        "outputId": "6470ff01-b741-47e7-f723-0966fd10174c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.488684506944036"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]], y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_p_norm = pipeline.predict(beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "rmse_euc_p_norm = np.sqrt(np.mean((beer_train_predicts_euc_p_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_p_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kccn4bJppgg0",
        "outputId": "0875fe6c-d91f-4be5-e3bc-8cd64a4b965c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.06072629247143"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]], y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_p_std = pipeline.predict(beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "rmse_man_p_std = np.sqrt(np.mean((beer_train_predicts_man_p_std - beer_train[\"ibu\"])**2))\n",
        "rmse_man_p_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3l4ML1OqQ2X",
        "outputId": "7ac2b400-3585-4e5b-9ad9-6f6a6894dfd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.157374503435793"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]], y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_p_norm = pipeline.predict(beer_train[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "rmse_man_p_norm = np.sqrt(np.mean((beer_train_predicts_man_p_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_man_p_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lGJDByuq3Nv",
        "outputId": "3ce686f8-e45c-48e7-9ba5-f5ad883b5eb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.097738903581902"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the standardizer gives a better prediction accuracy. This could be because standardizing tends to work better with outlier values."
      ],
      "metadata": {
        "id": "F0cp09VcnE5_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O3DcQAYGYtq"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Repeat Question 1, this time using the *cultural* features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.get_dummies(beer_train[[\"available\", \"glass\"]])"
      ],
      "metadata": {
        "id": "wpxNiKAGXE7g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_c_std = pipeline.predict(X_train)\n",
        "rmse_euc_c_std = np.sqrt(np.mean((beer_train_predicts_euc_c_std - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_c_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l6-fpY9YWuU",
        "outputId": "1ca40fd5-e914-4c94-966e-51fefa8e6f94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.36235247556609"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_c_std = pipeline.predict(X_train)\n",
        "rmse_man_c_std = np.sqrt(np.mean((beer_train_predicts_man_c_std - beer_train[\"ibu\"])**2))\n",
        "rmse_man_c_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ehjw82Ch6Th",
        "outputId": "d1342e31-5659-411d-b601-3965b9a5d38c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.322524824376387"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_c_norm = pipeline.predict(X_train)\n",
        "rmse_euc_c_norm = np.sqrt(np.mean((beer_train_predicts_euc_c_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_c_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y09Mm7qXiCHJ",
        "outputId": "83c3e970-e216-49da-8eaf-71f0f766808b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.77022554699036"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_c_norm = pipeline.predict(X_train)\n",
        "rmse_man_c_norm = np.sqrt(np.mean((beer_train_predicts_man_c_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_man_c_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXuRndUsie4z",
        "outputId": "9aed6cd1-63e3-48ac-b649-c772b0a5bb82"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.82081337988188"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rmse values are now all really close so it is hard to say if one if better than the others. They are also higher than the values when we used physical factors, this could be because of less factors used or less possible values since they are dummy variables."
      ],
      "metadata": {
        "id": "GxIsIiIqoeI4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgaFvqueY8Dc"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Finally, repeat Question 1, using *all* the features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.get_dummies(beer_train[[\"available\", \"glass\", \"abv\", \"originalGravity\", \"srm_quant\"]])"
      ],
      "metadata": {
        "id": "8Sr9o5QOixDP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_b_std = pipeline.predict(X_train)\n",
        "rmse_euc_b_std = np.sqrt(np.mean((beer_train_predicts_euc_b_std - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_b_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4VlJ6qDjDUP",
        "outputId": "85fb6250-c125-4133-ceab-dee3a390c1db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.519230953447774"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_b_std = pipeline.predict(X_train)\n",
        "rmse_man_b_std = np.sqrt(np.mean((beer_train_predicts_man_b_std - beer_train[\"ibu\"])**2))\n",
        "rmse_man_b_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzIaSCxzjIsP",
        "outputId": "043b31f9-20d5-4bdc-b97d-fdeeee7a7b0c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.136424168684055"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"euclidean\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_euc_b_norm = pipeline.predict(X_train)\n",
        "rmse_euc_b_norm = np.sqrt(np.mean((beer_train_predicts_euc_b_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_euc_b_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDCf6ArSjP_b",
        "outputId": "5f5edc20-5f9b-492c-bdf1-f175cc48a867"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.537310399404383"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(\n",
        "          Normalizer(),\n",
        "          KNeighborsRegressor(n_neighbors=20, metric=\"manhattan\")\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=beer_train[\"ibu\"])\n",
        "beer_train_predicts_man_b_norm = pipeline.predict(X_train)\n",
        "rmse_man_b_norm = np.sqrt(np.mean((beer_train_predicts_man_b_norm - beer_train[\"ibu\"])**2))\n",
        "rmse_man_b_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_xTI8yejb_2",
        "outputId": "a9edd2d4-3f4f-47ce-c98b-5152d0d6c11a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.101868918197216"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard scaler again performs slightly better. It appears to perform slightly better with manhattan distance, although this may not be significant. Interestingly, our numbers not quite as good as same metrics with the physical features only."
      ],
      "metadata": {
        "id": "x0Omfa-do_25"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_uFz0BaY8Ds"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Finally, let's determine the right value of $k$. Use the set of features, the distance metric, and the scaling method that you determined to be best (for $k=20$ nearest neighbors model) in Question 4. Fit $k$-nearest neighbor models for different values of $k$. Plot the training error and the estimated test error as functions of $k$, and determine the optimal value of $k$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because it gave us the best results in our training metrics, we will use standard scaler, manhattan distance, and only the physical features for our models."
      ],
      "metadata": {
        "id": "gIa61BFGpwxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beer_train_subset = beer_train.loc[:5000].copy()\n",
        "beer_test_subset = beer_train.loc[5000:].copy()"
      ],
      "metadata": {
        "id": "NWz1Y09227ZG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "model_accuracy = pd.DataFrame(columns=[\"K\", \"Train rmse\", \"Test rmse\"])\n",
        "for k in range(2, 40, 2):\n",
        "  pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=k, metric=\"manhattan\")\n",
        "  )\n",
        "\n",
        "  pipeline.fit(X=beer_train_subset[[\"abv\", \"originalGravity\", \"srm_quant\"]], y=beer_train_subset[\"ibu\"])\n",
        "  beer_train_predicts = pipeline.predict(beer_train_subset[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "  rmse_train = np.sqrt(mean_squared_error(beer_train_subset[\"ibu\"], beer_train_predicts))\n",
        "\n",
        "  beer_test_predicts = pipeline.predict(beer_test_subset[[\"abv\", \"originalGravity\", \"srm_quant\"]])\n",
        "  rmse_test = np.sqrt(mean_squared_error(beer_test_subset[\"ibu\"], beer_test_predicts))\n",
        "\n",
        "  model_accuracy = model_accuracy.append({\"K\": k, \"Train rmse\": rmse_train, \"Test rmse\": rmse_test}, ignore_index=True)"
      ],
      "metadata": {
        "id": "QJh_96__qDmP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_plot = model_accuracy.plot.scatter(x=\"K\", y=\"Train rmse\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "SUHy5Zm6r9QZ",
        "outputId": "0c689a6e-935f-4fbb-81f9-52445c3ff099"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATMUlEQVR4nO3dfWxdd33H8c/nNiYxpKwmMayLGwLt6LRVwYPQjQW2UgbLCgoPmWCRqhVULcAGFNiWbPwBBakMIp6EYGVhDQUG4WEutGNoG+IpoKFWCU1MeNA61pY6dEnqpCPeEs/p/e6PewyO5Ydj33se7v29X5Jl+9xrn2+Omk9+/Z7f73ccEQIApKNRdQEAgHIR/ACQGIIfABJD8ANAYgh+AEjMiqoLyGPt2rWxYcOGqssAgK5y8ODBhyJicPbxrgj+DRs26MCBA1WXAQBdxfb9cx2n1QMAiSH4ASAxBD8AJIbgB4DEEPwAkBiCHwBqanxiUocfeFjjE5Md/b1dMZ0TAFJz+6Gj2jUyqr5GQ1PNpnZv26itw+s68rsZ8QNAAdoZrY9PTGrXyKjOTjV1evKczk41tXNktGMjf0b8ADDL+MSkxk6d0dBAv9asXrnkn293tD526oz6Gg2dVfNnx/oaDY2dOrOsemYj+AFghnZDe+ZofTq4d46MavNla3OH9tBAv6aazfOOTTWbGhroz/8HWQCtHgA9peoWy/Rofabp0Xpea1av1O5tG7Wqr6ELV67Qqr6Gdm/b2JHRvsSIH0APqUOLpVOj9a3D67T5srVttZzmw4gfQE/oxGi9E6HdydH6mtUr9dRLLupo6EuM+AHUSDs3VTsxWp8O7Z2z/q9hqbUUOVrvBIIfQC2026apW4tlzeqVtQv8abR6AFSuE22abmix1AUjfgAdUXWbRqp/i6UuCH4AlS9Y6uS89Tq3WOqCVg+QuNsPHdXmd31V1/7dndr8rq/qjkNHl/TzdWvTYHGM+IGEdWKVKW2a7kPwA12u6t46bZruQ/ADXawOvfVOzX1HeQh+oEt1ok2TyoIlnK+w4Le9V9ILJR2PiCuyY8OSPixplaRzkv4kIu4qqgagl9Wtt06bpnsUOavnVklbZh3bLeltETEs6S3Z9wCWodO99V5esITzFRb8EbFf0snZhyU9Nvv6FyT9pKjzA92gnS2EmQKJ5Sq7x/8GSf9i+91q/aPzW/O90fYOSTskaf369eVUB5SoE89UpbeO5Sh7AddrJL0xIi6R9EZJt8z3xojYExGbImLT4OBgaQUCZejkM1Vp02Cpyg7+6yTdln39OUlXlnx+oGPaadN04ilNwHKV3er5iaTfkfR1SVdLuqfk8wMdUYf588ByFTbit71P0rclXW57zPb1kv5Y0ntsH5b0DmU9fKCbsDcNul1hI/6I2D7PS08v6pxAGeo2fx5YKlbuAkvE3jTodmzLjCQxfx4pY8SP5DB/Hqkj+JGUTmxsNo02DboVrR50peW2apg/DzDiRxdqp1XD/HmAET+6TLtz6LkxCzDiR5fpxBx6bswidQQ/StfOM2I71arhxixSRvCjVO1OpeT5rkD7CH6UplNTKWnVAO0h+FGaTu1xI9GqAdrBrB6UhqmUQD0Q/CgNUymBeqDVg1LRnweqR/CjdPTngWrR6gGAxBD8AJAYgh9L0s4DTADUAz1+5NaJB5gAqB4jfuTS7q6YAOqD4EcuPMAE6B0EP3Jh1S3QOwh+5MKqW6B3cHMXubHqFugNBD+WhFW3QPej1QMAiSH4E8LiKwASrZ5ksPgKwDRG/Alg8RWAmQj+BLD4CsBMhQW/7b22j9s+MuPYZ2wfyj7us32oqPPj51h8BWCmIkf8t0raMvNARLw8IoYjYljSiKTbCjw/Miy+AjBTYTd3I2K/7Q1zvWbbkl4m6eqizo/zsfgKwLSqZvU8W9KxiLhnvjfY3iFphyStX7++rLp6GouvAEjV3dzdLmnfQm+IiD0RsSkiNg0ODpZUFgD0vtJH/LZXSHqppKeXfW4AQDUj/t+V9MOIGKvg3ACQvCKnc+6T9G1Jl9ses3199tIfapE2DwCgOEXO6tk+z/FXFHXOXjY+McmMHAAdwV49XYB9dgB0Els21Bz77ADoNIK/5thnB0CnEfw1xz47ADqN4K859tkB0Gnc3O0C7LMDoJMI/i7BPjsAOoVWDwAkhuAHgMQQ/ACQGIIfABKzaPC75Vrbb8m+X2/7yuJLAwAUIc+I/28kPVOth6dI0mlJHyqsIgBAofJM5/yNiHia7bslKSJO2X5UwXUBAAqSZ8Q/ZfsCSSFJtgclNRf+EQBAXeUJ/g9I+rykx9u+SdK3JL2j0KoAAIVZtNUTEZ+0fVDScyVZ0osj4geFVwYAKESeWT2XSro3Ij4k6Yik59m+qPDKAACFyNPqGZH0iO3LJP2tpEskfarQqgAAhckT/M2IOCfppZI+GBF/IeniYssCABQl76ye7ZL+SNIXs2N9xZUEAChSnuB/pVoLuG6KiHttP0nSJ4otq7eMT0zq8AMP85xcALWQZ1bP9yW9fsb390p6V5FF9ZLbDx3VrpFR9TUammo2tXvbRm0dXld1WQASlmdWzwtt3237pO2f2j5t+6dlFNftxicmtWtkVGenmjo9eU5np5raOTLKyB9ApfK0et4v6TpJayLisRFxYUQ8tuC6esLYqTPqa5x/ifsaDY2dOlNRRQCQL/gfkHQkIqLoYnrN0EC/pprn724x1WxqaKC/oooAIN8mbTslfcn2NyT9rEcREe8trKoesWb1Su3etlE7Z/X4eXYugCrlCf6bJE1IWiWJXTmXaOvwOm2+bK3GTp3R0EA/oQ+gcnmC/5ci4orCK+lha1avJPAB1EaeHv+XbD+/8EoAAKXIE/yvkfTPts8wnRMAut+CwW+7IWlLRDQion8p0zlt77V93PaRWcdfZ/uHtr9ne3eb9QMAlmjB4I+IpqQPLvN33yppy8wDtp8j6UWSnhoRvybp3cv83QCAZcrT6vmK7W22vZRfHBH7JZ2cdfg1kt4ZEZPZe44v5XcCANqXJ/hfJelzkiY70ON/iqRn277T9jdsP2O+N9reYfuA7QMnTpxY5ukAALPl2aTtwg6f73GSflPSMyR91vaT51oVHBF7JO2RpE2bNrFqGAA6JM+Iv5PGJN0WLXdJakpaW3INAJC0soP/C5KeI0m2n6LWSuCHSq4BAJKWZ+XustjeJ+kqSWttj0l6q6S9kvZmUzz/T9J1bP4GAOXKFfy2L5D0hJnvj4gfL/QzEbF9npeuzV0dAKDjFg1+269Ta7R+TK2evCSFpI0F1gUAKEieEf8Nki6PiPGiiwEAFC/vg1j+u+hCAADlyDPi/09JX7f9T+JBLADQ9fIE/4+zj0eJB7EAQNfLs3L3bWUUAgAox7zBb/v9EfEG2/+o1iye80TE1kIrAwAUYqER/yeyz2ydDAA9ZN7gj4iD2edvlFcOAKBoeRZw/bKkv5b0q5JWTR+PiCcXWBcAoCB55vF/VNLNks6ptcHaxyX9fZFFAQCKkyf4+yPiK5IcEfdHxI2SXlBsWQCAouSZxz+ZPXT9HtuvlXRU0upiywIAFCXPiP8GSY+W9HpJT1drd83riiwKAFCcBUf82XbML4+IP5c0IemVpVQFACjMvCN+2ysi4hFJzyqxHgBAwRYa8d8l6WmS7rZ9h6TPSfqf6Rcj4raCawMAFCDPzd1VksYlXa3W1g3OPhP8ANCFFgr+x9t+k6Qj+nngT+M5uQDQpRYK/gvUmrbpOV5LJvjHJyY1duqMhgb6tWb1yqrLAYC2LRT8D0bE20urpIZuP3RUu0ZG1ddoaKrZ1O5tG7V1eF3VZQFAWxaaxz/XSD8Z4xOT2jUyqrNTTZ2ePKezU03tHBnV+MTk4j8MADW2UPA/t7Qqamjs1Bn1Nc6/PH2NhsZOnamoIgDojHmDPyJOlllI3QwN9Guq2Tzv2FSzqaGB/ooqAoDOyLNlQ5LWrF6p3ds2alVfQxeuXKFVfQ3t3raRG7wAul6eefzJ2jq8TpsvW8usHgA9heBfxJrVKwl8AD2FVg8AJIbgB4DEEPwAkBiCHwASU1jw295r+7jtIzOO3Wj7qO1D2cc1RZ0fADC3Ikf8t0raMsfx90XEcPbxpQLPDwCYQ2HBHxH7JSW9+hcA6qiKHv9rbY9mraCB+d5ke4ftA7YPnDhxosz6AKCnlR38N0u6VNKwpAclvWe+N0bEnojYFBGbBgcHy6oPAHpeqcEfEcci4pGIaEr6iKQryzw/AKDk4Ld98YxvX6LWYx0BACUqbK8e2/skXSVpre0xSW+VdJXtYbUe3XifpFcVdX4AwNwKC/6I2D7H4VuKOh8AIB9W7gJAYgh+AEgMwQ8AiSH4ASAxBD8AJIbgB4DEEPwAkBiCHwASQ/ADQGIIfgBIDMEPAIkh+AEgMQQ/ACSG4AeAxBD8AJAYgh8AEkPwA0BiCH4ASAzBDwCJIfgBIDEEPwAkhuAHgMQQ/ACQGIIfABJD8ANAYgh+AEgMwQ8AiSH4ASAxBD8AJIbgB4DEEPwAkJjCgt/2XtvHbR+Z47U/sx221xZ1fgDA3Ioc8d8qacvsg7YvkfR8ST8u8NwAgHkUFvwRsV/SyTleep+knZKiqHMDAOZXao/f9oskHY2Iwzneu8P2AdsHTpw4UUJ1AJCG0oLf9qMlvVnSW/K8PyL2RMSmiNg0ODhYbHEAkJAyR/yXSnqSpMO275M0JOk7tn+xxBoAIHkryjpRRHxX0uOnv8/Cf1NEPFRWDQCAYqdz7pP0bUmX2x6zfX1R5wIA5FfYiD8iti/y+oaizg0AmB8rdwEgMQQ/ACSG4AeAxBD8AJAYgh8AEkPwA0BiCH4ASAzBDwCJIfgBIDEEPwAkhuAHgMT0dPCPT0zq8AMPa3xisupSAKA2StuWuWy3HzqqXSOj6ms0NNVsave2jdo6vK7qsgCgcj054h+fmNSukVGdnWrq9OQ5nZ1qaufIKCN/AFCPBv/YqTPqa5z/R+trNDR26kxFFQFAffRk8A8N9Guq2Tzv2FSzqaGB/ooqAoD66MngX7N6pXZv26hVfQ1duHKFVvU1tHvbRq1ZvbLq0gCgcj17c3fr8Dptvmytxk6d0dBAP6EPAJmeDX6pNfIn8AHgfD3Z6gEAzI/gB4DEEPwAkBiCHwASQ/ADQGIcEVXXsCjbJyTdX3Udi1gr6aGqi8iBOjurW+qUuqdW6uycJ0bE4OyDXRH83cD2gYjYVHUdi6HOzuqWOqXuqZU6i0erBwASQ/ADQGII/s7ZU3UBOVFnZ3VLnVL31EqdBaPHDwCJYcQPAIkh+AEgMQR/m2zfZ/u7tg/ZPlB1PTPZ3mv7uO0jM449zvaXbd+TfR6ossasprnqvNH20ey6HrJ9TZU1ZjVdYvtrtr9v+3u2b8iO1+qaLlBnra6p7VW277J9OKvzbdnxJ9m+0/Z/2P6M7UdVWecitd5q+94Z13S46lrzoMffJtv3SdoUEbVbyGH7tyVNSPp4RFyRHdst6WREvNP2X0oaiIhdNazzRkkTEfHuKmubyfbFki6OiO/YvlDSQUkvlvQK1eiaLlDny1Sja2rbkh4TERO2+yR9S9INkt4k6baI+LTtD0s6HBE317TWV0v6YkT8Q5X1LRUj/h4WEfslnZx1+EWSPpZ9/TG1AqFS89RZOxHxYER8J/v6tKQfSFqnml3TBeqslWiZyL7tyz5C0tWSpoO08uspLVhrVyL42xeS/tX2Qds7qi4mhydExIPZ1/8l6QlVFrOI19oezVpBlbekZrK9QdKvS7pTNb6ms+qUanZNbV9g+5Ck45K+LOlHkh6OiHPZW8ZUk3+0ZtcaEdPX9Kbsmr7Pdlc8+Yngb9+zIuJpkn5f0p9mbYuuEK0+X11HLTdLulTSsKQHJb2n2nJ+zvZqSSOS3hARP535Wp2u6Rx11u6aRsQjETEsaUjSlZJ+peKS5jW7VttXSPortWp+hqTHSaq0bZoXwd+miDiafT4u6fNq/cdbZ8eyHvB0L/h4xfXMKSKOZX/RmpI+oppc16y/OyLpkxFxW3a4dtd0rjrrek0lKSIelvQ1Sc+UdJHt6cfCDkk6Wllhc5hR65asrRYRMSnpo6rRNV0Iwd8G24/Jbp7J9mMkPV/SkYV/qnJ3SLou+/o6SbdXWMu8poM08xLV4LpmN/hukfSDiHjvjJdqdU3nq7Nu19T2oO2Lsq/7JT1PrfsRX5P0B9nbKr+e0ry1/nDGP/hW615E5f+d5sGsnjbYfrJao3yp9eD6T0XETRWWdB7b+yRdpdb2scckvVXSFyR9VtJ6tba6fllEVHpjdZ46r1KrJRGS7pP0qhl99ErYfpakb0r6rqRmdvjNavXPa3NNF6hzu2p0TW1vVOvm7QVqDUI/GxFvz/5efVqt1sndkq7NRtSVWaDWr0oalGRJhyS9esZN4Noi+AEgMbR6ACAxBD8AJIbgB4DEEPwAkBiCHwASQ/ADy2B7YsbX19j+d9tPrLImIK8Vi78FwHxsP1fSByT9XkTcX3U9QB4EP7BM2b5MH5F0TUT8qOp6gLxYwAUsg+0pSaclXRURo1XXAywFPX5geaYk/Zuk66suBFgqgh9YnqZaT7S60vabqy4GWAp6/MAyRcT/2n6BpG/aPhYRt1RdE5AHwQ+0ISJO2t4iab/tExFxR9U1AYvh5i4AJIYePwAkhuAHgMQQ/ACQGIIfABJD8ANAYgh+AEgMwQ8Aifl/rI9Dyv5SWvkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_plot = model_accuracy.plot.scatter(x=\"K\", y=\"Test rmse\", c=\"red\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rQKumdCJ-AnE",
        "outputId": "0ec03d69-d6b8-4cab-a245-b7951062ef85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the optimal value of K is 10, using the test data. The optimal value of K appears to be 2 with the training data, but this make sense because since we are predicting on the training data itself, as we include more neighbors it will get less accurate. For this reason, it is much better to use the test metrics."
      ],
      "metadata": {
        "id": "AAxv3TjFs49S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhRFqKSDY8D2"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "- Copy this notebook to your own Drive, if you have not already.\n",
        "- Restart this notebook and run the cells from beginning to end. \n",
        "  - Go to Runtime > Restart and Run All.\n",
        "- Rename this notebook by clicking on \"DATA 301 Lab 4 - YOUR NAMES HERE\" at the very top of this page. Replace \"YOUR NAMES HERE\" with the first and last names of you (and your partners, for Phase 2).\n",
        "- Get the link to your notebook:\n",
        "  - Click on \"Share\" at the top-right. \n",
        "  - Change the settings to \"Anyone with the link can view\". \n",
        "  - Copy the sharing link into Canvas."
      ]
    }
  ]
}